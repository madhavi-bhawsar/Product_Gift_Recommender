{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8a799f-e288-413f-bad0-b7de90885e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Using cached surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
      "Requirement already satisfied: scikit-surprise in c:\\users\\hp\\miniconda3\\lib\\site-packages (from surprise) (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from scikit-surprise->surprise) (1.11.1)\n",
      "Installing collected packages: surprise\n",
      "Successfully installed surprise-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748750d9-eb8b-4431-bbd6-4f3bfda81ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Using cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2023.8.8-cp311-cp311-win_amd64.whl (268 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\miniconda3\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Using cached tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Using cached safetensors-0.3.2-cp311-cp311-win_amd64.whl (266 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Collecting fsspec (from huggingface-hub<1.0,>=0.14.1->transformers)\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Installing collected packages: tokenizers, safetensors, regex, fsspec, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.12.2 fsspec-2023.6.0 huggingface-hub-0.16.4 regex-2023.8.8 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/huggingface-hub/\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad3d66c-7041-46c9-89bb-6ef15d031515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Faker\n",
      "  Using cached Faker-19.3.0-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from Faker) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from python-dateutil>=2.4->Faker) (1.16.0)\n",
      "Installing collected packages: Faker\n",
      "Successfully installed Faker-19.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d79e017f-68c2-4eb4-bf99-f889b7bcdd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.0.1-cp311-cp311-win_amd64.whl (172.3 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\miniconda3\\lib\\site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\miniconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, torch\n",
      "Successfully installed mpmath-1.3.0 networkx-3.1 sympy-1.12 torch-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb2bfa8e-06ad-432a-beb7-eab1af3ad332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.1-cp311-cp311-win_amd64.whl (23.9 MB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from gensim) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from gensim) (1.11.1)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Using cached smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.1 smart-open-6.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6df23c7d-051a-432a-a356-7756651468cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post7.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0.post7-py3-none-any.whl size=2971 sha256=bc0cd497489d0c75e2928b18baf1fea9127134b170729f0319d7369e4bf023c9\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\08\\17\\db\\46486df299847133f69165c029fe388fac45781eb5d436c569\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0.post7\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7fadc5d-65cd-4b5b-ad25-b2eac571ad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.3.0-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.3.0 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "487b4b4b-1f7a-42bd-a8bf-719fc6882399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "from faker import Faker\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Generate realistic user profiles\n",
    "num_users = 40\n",
    "users = [\n",
    "    {\n",
    "        'user_id': i + 1,\n",
    "        'age': fake.random_int(18, 60),\n",
    "        'birth_date': fake.date_of_birth(tzinfo=None, minimum_age=18, maximum_age=60),  # Generate birth date\n",
    "        'city': fake.city(),\n",
    "        'name': fake.name()\n",
    "    }\n",
    "    for i in range(num_users)\n",
    "]\n",
    "user_df = pd.DataFrame(users)\n",
    "\n",
    "products_per_category = 15\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertForMaskedLM.from_pretrained(bert_model_name)\n",
    "\n",
    "\n",
    "product_names_per_category = {\n",
    "    'Electronics': [\"Smartphone\", \"Laptop\", \"Headphones\", \"Camera\", \"Gaming Console\", \"Tablet\", \"TV\", \"Charger\", \"Power Bank\", \"Wireless Earbuds\", \"Smartwatch\", \"Bluetooth Speaker\", \"Mouse\", \"Keyboard\", \"Monitor\"],\n",
    "    'Books': [\"Mystery Novel\", \"Science Fiction Book\", \"Cookbook\", \"Self-help Book\", \"Fantasy Novel\", \"Biography\", \"Thriller\", \"Romance Novel\", \"Historical Fiction\", \"Poetry Book\", \"Non-fiction Book\", \"Classic Literature\", \"Comic Book\", \"Graphic Novel\", \"Children's Book\"],\n",
    "    'Groceries': [\"Fresh Apples\", \"Whole Wheat Bread\", \"Organic Milk\", \"Organic Eggs\", \"Fresh Vegetables\", \"Lean Chicken Breast\", \"Greek Yogurt\", \"Cereal\", \"Granola Bars\", \"Frozen Fruits\", \"Canned Soup\", \"Brown Rice\", \"Olive Oil\", \"Pasta\", \"Spices\"],\n",
    "    'Clothes': [\"Casual T-shirt\", \"Jeans\", \"Sneakers\", \"Dress Shirt\", \"Dress Shoes\", \"Blouse\", \"Shorts\", \"Sports Bra\", \"Running Shoes\", \"Hoodie\", \"Jacket\", \"Activewear Leggings\", \"Swimsuit\", \"Formal Dress\", \"Polo Shirt\"],\n",
    "    'Beauty': [\"Moisturizing Cream\", \"Anti-Aging Serum\", \"Cleansing Oil\", \"Face Mask\", \"Sunscreen\", \"Perfume\", \"Shampoo\", \"Conditioner\", \"Hair Styling Gel\", \"Lipstick\", \"Eyeshadow Palette\", \"Mascara\", \"Nail Polish\", \"Foundation\", \"Blush\"]\n",
    "}\n",
    "# Generate products for each category with generated descriptions\n",
    "categories = list(product_names_per_category.keys())\n",
    "products_per_category = len(product_names_per_category['Electronics'])  # Assuming all categories have the same number of products\n",
    "\n",
    "products = []\n",
    "for cat in categories:\n",
    "    product_names = product_names_per_category[cat]\n",
    "    for i, product_name in enumerate(product_names, start=1):\n",
    "        product_id = (categories.index(cat) * products_per_category) + i\n",
    "\n",
    "        # Generate product description using BERT\n",
    "        input_text = f\"Product: {product_name} Category: {cat}\"\n",
    "        inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = bert_model(**inputs)\n",
    "            masked_lm_logits = outputs.logits\n",
    "            predicted_tokens = torch.argmax(masked_lm_logits, dim=-1)\n",
    "            generated_description = tokenizer.decode(predicted_tokens[0])\n",
    "\n",
    "        products.append({'product_id': product_id, 'category': cat,\n",
    "                         'price': np.random.randint(10, 500),\n",
    "                         'brand': fake.company(),\n",
    "                         'name': product_name,\n",
    "                         'description': generated_description})\n",
    "\n",
    "product_df = pd.DataFrame(products)\n",
    "\n",
    "# Generate cart data\n",
    "cart_data = []\n",
    "for user_id in user_df['user_id']:\n",
    "    num_cart_items = np.random.randint(0, 5)  # Random number of items in the cart\n",
    "    cart_items = np.random.choice(product_df['product_id'], num_cart_items, replace=False)\n",
    "    cart_data.extend([{'user_id': user_id, 'product_id': item_id} for item_id in cart_items])\n",
    "\n",
    "cart_df = pd.DataFrame(cart_data)\n",
    "\n",
    "# Generate realistic interactions (purchases and other interactions)\n",
    "interactions = []\n",
    "for user_id in user_df['user_id']:\n",
    "    num_purchases = np.random.randint(0, 10)  # Random number of purchases\n",
    "    purchase_dates = [fake.date_between(start_date='-6M', end_date='today') for _ in range(num_purchases)]\n",
    "\n",
    "    for purchase_date in purchase_dates:\n",
    "        product_id = np.random.choice(product_df['product_id'])\n",
    "        rating = np.random.randint(4, 6)  # Higher ratings for purchases\n",
    "        interactions.append({'user_id': user_id, 'product_id': product_id,\n",
    "                             'rating': rating, 'purchase_date': purchase_date})\n",
    "\n",
    "interaction_df = pd.DataFrame(interactions)\n",
    "\n",
    "# Generate a user with no interactions and an empty cart\n",
    "new_user = {'user_id': 41, 'age': fake.random_int(18, 60), 'city': fake.city(), 'name': fake.name()}\n",
    "user_df = pd.concat([user_df, pd.DataFrame([new_user])], ignore_index=True)\n",
    "\n",
    "# Generate cart data for the new user (empty cart)\n",
    "empty_cart_data = [{'user_id': 41, 'product_id': None}]  # Use None to represent an empty cart\n",
    "cart_df = pd.concat([cart_df, pd.DataFrame(empty_cart_data)], ignore_index=True)\n",
    "\n",
    "new_user = {\n",
    "    'user_id': 42,\n",
    "    'age': 20,  # Set a reasonable age for consistency with the birth date\n",
    "    'birth_date': datetime.strptime('2001-08-30', '%Y-%m-%d').date(),\n",
    "    'city': fake.city(),\n",
    "    'name': fake.name()\n",
    "}\n",
    "user_df = pd.concat([user_df, pd.DataFrame([new_user])], ignore_index=True)\n",
    "\n",
    "# Generate cart data for the new user (with items)\n",
    "new_user_cart_items = [2, 5, 10, 15]  # Product IDs to add to the cart\n",
    "cart_data_new_user = [{'user_id': 42, 'product_id': item_id} for item_id in new_user_cart_items]\n",
    "cart_df = pd.concat([cart_df, pd.DataFrame(empty_cart_data)], ignore_index=True)\n",
    "\n",
    "# Generate interactions for the new user\n",
    "interactions_new_user = []\n",
    "for _ in range(20):  # Generate 20 interactions for the new user\n",
    "    product_id = np.random.choice(product_df['product_id'])\n",
    "    rating = np.random.randint(1, 6)  # Generate random ratings\n",
    "    purchase_date = fake.date_between(start_date='-6M', end_date='today')\n",
    "    interactions_new_user.append({'user_id': 42, 'product_id': product_id,\n",
    "                                  'rating': rating, 'purchase_date': purchase_date})\n",
    "\n",
    "new_interactions_df = pd.DataFrame(interactions_new_user)\n",
    "interaction_df = pd.concat([interaction_df, new_interactions_df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Save the generated dataframes as CSV files\n",
    "user_df.to_csv('user_data.csv', index=False)\n",
    "product_df.to_csv('product_data.csv', index=False)\n",
    "cart_df.to_csv('cart_data.csv', index=False)\n",
    "interaction_df.to_csv('interaction_data.csv', index=False)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Train a Word2Vec model on the product descriptions\n",
    "corpus = [text.split() for text in product_df['description']]  # Use 'description' instead of 'product_description'\n",
    "w2v_model = Word2Vec(corpus, vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "# Function to get the vector representation of a product's description\n",
    "def get_product_vector(description):\n",
    "    vector_sum = np.zeros(100)  # Assuming vector_size is 100\n",
    "    words = description.split()\n",
    "    for word in words:\n",
    "        if word in w2v_model.wv:\n",
    "            vector_sum += w2v_model.wv[word]\n",
    "    return vector_sum\n",
    "\n",
    "# Create product vectors\n",
    "product_vectors = [get_product_vector(desc) for desc in product_df['description']]  # Use 'description' instead of 'product_description'\n",
    "\n",
    "# Calculate cosine similarity scores using product vectors\n",
    "product_similarity_scores_w2v = cosine_similarity(product_vectors, product_vectors)\n",
    "\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name)\n",
    "# Tokenize and obtain BERT embeddings for product descriptions\n",
    "product_embeddings = []\n",
    "for description in product_df['description']:\n",
    "    inputs = tokenizer(description, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "        product_embeddings.append(embeddings)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Compute similarity scores using cosine similarity between BERT embeddings\n",
    "product_similarity_scores_bert = cosine_similarity(product_embeddings)\n",
    "combined_similarity_scores = 0.7 * product_similarity_scores_w2v + 0.3 * product_similarity_scores_bert\n",
    "\n",
    "# Normalize the combined scores to [0, 1]\n",
    "max_score = np.max(combined_similarity_scores)\n",
    "min_score = np.min(combined_similarity_scores)\n",
    "normalized_scores = (combined_similarity_scores - min_score) / (max_score - min_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f227b1a1-2536-443d-8567-81bb90ae8e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Flask\n",
      "  Using cached Flask-2.3.2-py3-none-any.whl (96 kB)\n",
      "Collecting Werkzeug>=2.3.3 (from Flask)\n",
      "  Using cached werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from Flask) (3.1.2)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask)\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting click>=8.1.3 (from Flask)\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask)\n",
      "  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\miniconda3\\lib\\site-packages (from click>=8.1.3->Flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from Jinja2>=3.1.2->Flask) (2.1.3)\n",
      "Installing collected packages: Werkzeug, itsdangerous, click, blinker, Flask\n",
      "Successfully installed Flask-2.3.2 Werkzeug-2.3.7 blinker-1.6.2 click-8.1.7 itsdangerous-2.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "601493f4-71da-418f-b6c4-badb3c85a36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 0.4029\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader, KNNBasic, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load your interaction data\n",
    "interaction_df = pd.read_csv('interaction_data.csv')\n",
    "\n",
    "# Prepare data for Surprise library\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(interaction_df[['user_id', 'product_id', 'rating']], reader)\n",
    "\n",
    "# Build trainset\n",
    "trainset = data.build_full_trainset()\n",
    "testset = trainset.build_anti_testset()\n",
    "# Build and train a k-Nearest Neighbors collaborative filtering model\n",
    "cf_model = KNNBasic(k=50, sim_options={'user_based': False})\n",
    "cf_model.fit(trainset)\n",
    "\n",
    "# Save the collaborative filtering model using pickle\n",
    "cf_model_path = 'cf_model.pkl'\n",
    "with open(cf_model_path, 'wb') as file:\n",
    "    pickle.dump(cf_model, file)\n",
    "# Make predictions and evaluate accuracy\n",
    "cf_predictions = cf_model.test(testset)\n",
    "cf_rmse = accuracy.rmse(cf_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9910034-7592-45e3-97dc-0f00c2405ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa5f8feb-7ab9-45d7-abc7-48c09af57183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.0-cp311-cp311-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl (276.6 MB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached h5py-3.9.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting numpy<=1.24.3,>=1.22 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached numpy-1.24.3-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached protobuf-4.24.1-cp310-abi3-win_amd64.whl (430 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached wrapt-1.15.0-cp311-cp311-win_amd64.whl (36 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached grpcio-1.57.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.29.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.7)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, numpy, markdown, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, opt-einsum, h5py, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.57.0 h5py-3.9.0 libclang-16.0.6 markdown-3.4.4 numpy-1.24.3 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.24.1 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 typing-extensions-4.5.0 wrapt-1.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3a3a4c7-02e8-4bd7-b9d1-03d231a44a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 - 1s - loss: 20.3277 - val_loss: 14.1892 - 868ms/epoch - 174ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 19.4478 - val_loss: 13.5306 - 38ms/epoch - 8ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 18.4653 - val_loss: 12.7148 - 41ms/epoch - 8ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 17.2554 - val_loss: 11.7062 - 38ms/epoch - 8ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 15.4589 - val_loss: 10.4516 - 42ms/epoch - 8ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 13.1078 - val_loss: 8.8880 - 44ms/epoch - 9ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 10.0883 - val_loss: 7.0106 - 43ms/epoch - 9ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 6.7659 - val_loss: 4.9472 - 40ms/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 3.2565 - val_loss: 3.1269 - 40ms/epoch - 8ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 1.5099 - val_loss: 2.0740 - 35ms/epoch - 7ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 2.5663 - val_loss: 1.8382 - 38ms/epoch - 8ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 1.6020 - val_loss: 1.9081 - 36ms/epoch - 7ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 1.4734 - val_loss: 2.1166 - 40ms/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 1.1341 - val_loss: 2.2992 - 34ms/epoch - 7ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 1.5227 - val_loss: 2.3366 - 36ms/epoch - 7ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 1.3221 - val_loss: 2.2375 - 37ms/epoch - 7ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 1.0895 - val_loss: 2.0794 - 60ms/epoch - 12ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 1.1330 - val_loss: 1.9414 - 41ms/epoch - 8ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 1.2783 - val_loss: 1.8654 - 38ms/epoch - 8ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 1.2854 - val_loss: 1.9250 - 39ms/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 1.2108 - val_loss: 2.0072 - 43ms/epoch - 9ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 1.0745 - val_loss: 1.9435 - 41ms/epoch - 8ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 1.3031 - val_loss: 1.8386 - 35ms/epoch - 7ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 1.1296 - val_loss: 1.8031 - 41ms/epoch - 8ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 1.2357 - val_loss: 1.8478 - 38ms/epoch - 8ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 1.1121 - val_loss: 1.9662 - 40ms/epoch - 8ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 1.0743 - val_loss: 1.9709 - 37ms/epoch - 7ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 1.2041 - val_loss: 1.9515 - 39ms/epoch - 8ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.9955 - val_loss: 1.8614 - 39ms/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 1.0517 - val_loss: 1.7699 - 41ms/epoch - 8ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.9427 - val_loss: 1.7995 - 36ms/epoch - 7ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.9940 - val_loss: 1.9110 - 38ms/epoch - 8ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 1.1842 - val_loss: 1.9882 - 36ms/epoch - 7ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.9076 - val_loss: 1.9360 - 36ms/epoch - 7ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.9394 - val_loss: 1.7724 - 37ms/epoch - 7ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 0.9635 - val_loss: 1.6742 - 35ms/epoch - 7ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 1.3749 - val_loss: 1.7514 - 38ms/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.9851 - val_loss: 1.9558 - 40ms/epoch - 8ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 1.0111 - val_loss: 1.9802 - 37ms/epoch - 7ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 1.0739 - val_loss: 1.8739 - 39ms/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 1.0122 - val_loss: 1.7545 - 41ms/epoch - 8ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.8623 - val_loss: 1.6951 - 39ms/epoch - 8ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 1.0764 - val_loss: 1.7873 - 35ms/epoch - 7ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.9874 - val_loss: 1.8541 - 43ms/epoch - 9ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.8318 - val_loss: 1.8365 - 36ms/epoch - 7ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.9156 - val_loss: 1.7268 - 34ms/epoch - 7ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 1.2527 - val_loss: 1.6693 - 38ms/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.9526 - val_loss: 1.7777 - 33ms/epoch - 7ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.9101 - val_loss: 1.8362 - 34ms/epoch - 7ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.8570 - val_loss: 1.8668 - 48ms/epoch - 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Flatten, Dense, Concatenate, Dropout\n",
    "\n",
    "# Define the number of products\n",
    "num_users = len(user_df)\n",
    "num_products = len(product_df)\n",
    "\n",
    "# Create a dictionary to map user and product IDs to indices\n",
    "user_id_to_index = {user_id: index for index, user_id in enumerate(user_df['user_id'])}\n",
    "product_id_to_index = {product_id: index for index, product_id in enumerate(product_df['product_id'])}\n",
    "\n",
    "# Map user and product IDs in interaction data to their respective indices\n",
    "interaction_df['user_index'] = interaction_df['user_id'].map(user_id_to_index)\n",
    "interaction_df['product_index'] = interaction_df['product_id'].map(product_id_to_index)\n",
    "\n",
    "# Separate user and product inputs\n",
    "user_input = Sequential()\n",
    "user_input.add(Embedding(num_users, 50, input_length=1))\n",
    "\n",
    "product_input = Sequential()\n",
    "product_input.add(Embedding(num_products, 50, input_length=1))\n",
    "\n",
    "# Concatenate user and product embeddings\n",
    "merged = Concatenate()([user_input.output, product_input.output])\n",
    "flatten = Flatten()(merged)\n",
    "\n",
    "# Build the neural network for regression\n",
    "dl_model = Dense(128, activation='relu')(flatten)\n",
    "dl_model = Dropout(0.5)(dl_model)\n",
    "dl_model = Dense(64, activation='relu')(dl_model)\n",
    "dl_model = Dropout(0.5)(dl_model)\n",
    "dl_model = Dense(1, activation='linear')(dl_model)  # Linear activation for regression\n",
    "\n",
    "model = Model(inputs=[user_input.input, product_input.input], outputs=dl_model)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')  # Use mean squared error for regression\n",
    "\n",
    "# Map user and product indices to arrays for training\n",
    "user_indices = interaction_df['user_index'].values\n",
    "product_indices = interaction_df['product_index'].values\n",
    "train_labels = interaction_df['rating'].values\n",
    "\n",
    "# Train the deep learning model\n",
    "model.fit([user_indices, product_indices], train_labels, epochs=50, batch_size=32, validation_split=0.2, verbose=2)\n",
    "\n",
    "# Save the complete model using the model save function\n",
    "dl_model_path = 'dl_model.h5'\n",
    "model.save(dl_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40f8b287-778a-4f64-bd35-712e6c0ba60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "    product_id     category  price                            brand  \\\n",
      "15          16        Books    443  Chambers, Schneider and Alvarez   \n",
      "13          14  Electronics    192                    Warren-Morris   \n",
      "3            4  Electronics     23      Carpenter, Fisher and Brown   \n",
      "8            9  Electronics     91          Doyle, Moore and Fuller   \n",
      "10          11  Electronics    456                   Palmer-Lambert   \n",
      "17          18        Books     32                        Booth Inc   \n",
      "18          19        Books    208                    Parker-Taylor   \n",
      "16          17        Books    363                     Harvey Group   \n",
      "21          22        Books    438                    Vaughn-Barton   \n",
      "23          24        Books    248         Cruz, Stephens and Young   \n",
      "43          44    Groceries    318         Chavez, Lucero and Haney   \n",
      "38          39    Groceries     38                         Bass LLC   \n",
      "32          33    Groceries    144        Todd, Sullivan and Abbott   \n",
      "31          32    Groceries    270                       Mata-Jones   \n",
      "36          37    Groceries    395            Bass, Clark and Allen   \n",
      "59          60      Clothes    287    Phillips, Waters and Oconnell   \n",
      "50          51      Clothes     67      Randall, Johnston and Stone   \n",
      "57          58      Clothes    338                     Turner-Rivas   \n",
      "56          57      Clothes    128                Alexander-Collier   \n",
      "55          56      Clothes    111                      Jones Group   \n",
      "61          62       Beauty     67                   Harrington LLC   \n",
      "65          66       Beauty    387      Aguilar, Jones and Erickson   \n",
      "68          69       Beauty    127           Ward, Hayes and Kelley   \n",
      "63          64       Beauty    108                  Schneider-Jones   \n",
      "64          65       Beauty    239       Brooks, Howard and Johnson   \n",
      "\n",
      "                    name                                        description  \n",
      "15         Mystery Novel               .. : mystery novel category : books.  \n",
      "13              Keyboard              .. : keyboard category : electronics.  \n",
      "3                 Camera                .. : camera category : electronics.  \n",
      "8             Power Bank                 .. :. bank category : electronics.  \n",
      "10            Smartwatch                 .. :.watch category : electronics.  \n",
      "17              Cookbook                       .. : cook. category : books.  \n",
      "18        Self-help Book            .. : self - help book category : books.  \n",
      "16  Science Fiction Book        .. : science fiction book category : books.  \n",
      "21              Thriller                    .. : thriller category : books.  \n",
      "23    Historical Fiction          .. : historical fiction category : books.  \n",
      "43                 Pasta                   .. : pasta category : groceries.  \n",
      "38          Granola Bars            .. : granola bars category : groceries.  \n",
      "32          Organic Milk            .. : organic milk category : groceries.  \n",
      "31     Whole Wheat Bread       .. : whole wheat bread category : groceries.  \n",
      "36          Greek Yogurt              .. : greek.gurt category : groceries.  \n",
      "59            Polo Shirt                .. : polo shirt category : clothes.  \n",
      "50                Blouse                    .. : blouse category : clothes.  \n",
      "57              Swimsuit                   . s : swim : category : clothes.  \n",
      "56   Activewear Leggings  . product : activewear leggings category : clo...  \n",
      "55                Jacket                    .. : jacket category : clothes.  \n",
      "61      Anti-Aging Serum  . product : anti - aging serum category : beauty.  \n",
      "65               Perfume                    .. : perfume category : beauty.  \n",
      "68      Hair Styling Gel          . product : hair & gel category : beauty.  \n",
      "63             Face Mask           . product : face mask category : beauty.  \n",
      "64             Sunscreen            . product : suncreen category : beauty.  \n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(user_id, num_per_category=5):\n",
    "    # Get user's past interactions\n",
    "    user_interactions = interaction_df[interaction_df['user_id'] == user_id]['product_id'].tolist()\n",
    "\n",
    "    # Content-Based Filtering\n",
    "    product_indices = product_df[product_df['product_id'].isin(user_interactions)].index\n",
    "    content_based_scores = normalized_scores[product_indices].sum(axis=0)\n",
    "\n",
    "    # Collaborative Filtering\n",
    "    cf_scores = np.zeros(num_products)\n",
    "    for prod_id in range(num_products):\n",
    "        cf_scores[prod_id] = cf_model.predict(user_id, prod_id).est\n",
    "\n",
    "    # Deep Learning\n",
    "    dl_input = np.array([[user_id]] * num_products)  # Repeat user_id for all products\n",
    "    dl_scores = model.predict([dl_input, np.arange(num_products)])\n",
    "\n",
    "    # Combine the scores from different models\n",
    "    combined_scores = content_based_scores + cf_scores + dl_scores.flatten()\n",
    "\n",
    "    # Create a dataframe for combined scores\n",
    "    combined_scores_df = pd.DataFrame({'product_id': np.arange(num_products), 'combined_score': combined_scores})\n",
    "\n",
    "    # Get top products from each category\n",
    "    top_products_per_category = []\n",
    "    for category in categories:\n",
    "        category_products = product_df[product_df['category'] == category]\n",
    "        category_scores = combined_scores_df[combined_scores_df['product_id'].isin(category_products['product_id'])]\n",
    "        top_products = category_scores.nlargest(num_per_category, 'combined_score')['product_id'].tolist()\n",
    "        top_products_per_category.extend(top_products)\n",
    "\n",
    "    return top_products_per_category\n",
    "\n",
    "# Example usage\n",
    "user_id = 10\n",
    "recommended_product_ids = get_recommendations(user_id, num_per_category=5)\n",
    "recommended_products = product_df.loc[recommended_product_ids]\n",
    "print(recommended_products)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f6a7f5d-7ebc-45f8-9f8c-72ff4695b095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 4ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 970us/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 860us/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 3ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 1ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "3/3 [==============================] - 0s 2ms/step\n",
      "\n",
      "Hybrid Model Evaluation:\n",
      "Average Accuracy: 0.63\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error\n",
    "\n",
    "# Generate test interactions\n",
    "num_test_interactions = 1000\n",
    "test_interactions = []\n",
    "for _ in range(num_test_interactions):\n",
    "    user_id = np.random.choice(num_users)\n",
    "    product_id = np.random.choice(num_products)\n",
    "    rating = np.random.randint(1, 6)\n",
    "    test_interactions.append({'user_id': user_id, 'product_id': product_id, 'rating': rating})\n",
    "\n",
    "test_interaction_df = pd.DataFrame(test_interactions)\n",
    "\n",
    "# Reshape test data\n",
    "test_user_ids = test_interaction_df['user_id'].values.reshape(-1, 1)\n",
    "test_product_ids = test_interaction_df['product_id'].values.reshape(-1, 1)\n",
    "\n",
    "# Predict using the model\n",
    "test_predictions = model.predict([test_user_ids, test_product_ids])\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "test_labels = test_interaction_df['rating'].values\n",
    "rmse = np.sqrt(mean_squared_error(test_labels, test_predictions))\n",
    "\n",
    "# Hybrid Model Evaluation\n",
    "accuracy_scores = []\n",
    "\n",
    "for user_id in test_user_ids.flatten():\n",
    "    user_actual_interactions = test_interaction_df[test_interaction_df['user_id'] == user_id]\n",
    "    recommended_product_ids = get_recommendations(user_id, num_per_category=5)\n",
    "    recommended_product_ids = set(recommended_product_ids)  # Convert to set for faster lookup\n",
    "    binary_recommendations = [1 if prod_id in recommended_product_ids else 0 for prod_id in range(num_products)]\n",
    "\n",
    "    # Convert actual interaction ratings to binary values\n",
    "    binary_actual_interactions = (user_actual_interactions['rating'] > 3).astype(int).tolist()\n",
    "\n",
    "    # Ensure both lists have the same length as the number of products\n",
    "    binary_recommendations.extend([0] * (num_products - len(binary_recommendations)))\n",
    "    binary_actual_interactions.extend([0] * (num_products - len(binary_actual_interactions)))\n",
    "\n",
    "    accuracy = accuracy_score(binary_actual_interactions, binary_recommendations)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "print(\"\\nHybrid Model Evaluation:\")\n",
    "print(f\"Average Accuracy: {average_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd5eaa73-c240-419c-8973-8d3fee34e43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "Category: Electronics\n",
      "Rank: 1, Product: 13, Score: 11.55\n",
      "Rank: 2, Product: 12, Score: 11.41\n",
      "Rank: 3, Product: 3, Score: 11.40\n",
      "Rank: 4, Product: 6, Score: 11.33\n",
      "Rank: 5, Product: 5, Score: 11.30\n",
      "Rank: 6, Product: 10, Score: 11.16\n",
      "Rank: 7, Product: 8, Score: 11.12\n",
      "Rank: 8, Product: 7, Score: 10.88\n",
      "Rank: 9, Product: 1, Score: 10.87\n",
      "Rank: 10, Product: 14, Score: 10.80\n",
      "Rank: 11, Product: 15, Score: 10.77\n",
      "Rank: 12, Product: 9, Score: 10.27\n",
      "Rank: 13, Product: 11, Score: 10.17\n",
      "Rank: 14, Product: 2, Score: 10.13\n",
      "Rank: 15, Product: 4, Score: 10.10\n",
      "\n",
      "Category: Books\n",
      "Rank: 1, Product: 17, Score: 10.89\n",
      "Rank: 2, Product: 23, Score: 10.71\n",
      "Rank: 3, Product: 21, Score: 10.47\n",
      "Rank: 4, Product: 18, Score: 10.44\n",
      "Rank: 5, Product: 20, Score: 10.35\n",
      "Rank: 6, Product: 22, Score: 10.27\n",
      "Rank: 7, Product: 16, Score: 10.14\n",
      "Rank: 8, Product: 27, Score: 10.03\n",
      "Rank: 9, Product: 24, Score: 10.03\n",
      "Rank: 10, Product: 28, Score: 9.72\n",
      "Rank: 11, Product: 19, Score: 9.61\n",
      "Rank: 12, Product: 30, Score: 9.59\n",
      "Rank: 13, Product: 26, Score: 9.41\n",
      "Rank: 14, Product: 25, Score: 9.10\n",
      "Rank: 15, Product: 29, Score: 9.09\n",
      "\n",
      "Category: Groceries\n",
      "Rank: 1, Product: 43, Score: 12.18\n",
      "Rank: 2, Product: 32, Score: 11.17\n",
      "Rank: 3, Product: 34, Score: 10.98\n",
      "Rank: 4, Product: 33, Score: 10.60\n",
      "Rank: 5, Product: 37, Score: 10.59\n",
      "Rank: 6, Product: 38, Score: 10.54\n",
      "Rank: 7, Product: 36, Score: 10.48\n",
      "Rank: 8, Product: 39, Score: 10.43\n",
      "Rank: 9, Product: 40, Score: 10.37\n",
      "Rank: 10, Product: 31, Score: 10.34\n",
      "Rank: 11, Product: 41, Score: 10.21\n",
      "Rank: 12, Product: 44, Score: 9.84\n",
      "Rank: 13, Product: 42, Score: 9.57\n",
      "Rank: 14, Product: 45, Score: 9.28\n",
      "Rank: 15, Product: 35, Score: 8.89\n",
      "\n",
      "Category: Clothes\n",
      "Rank: 1, Product: 50, Score: 11.71\n",
      "Rank: 2, Product: 59, Score: 11.67\n",
      "Rank: 3, Product: 48, Score: 11.32\n",
      "Rank: 4, Product: 53, Score: 11.21\n",
      "Rank: 5, Product: 57, Score: 11.14\n",
      "Rank: 6, Product: 55, Score: 11.12\n",
      "Rank: 7, Product: 46, Score: 10.80\n",
      "Rank: 8, Product: 56, Score: 10.76\n",
      "Rank: 9, Product: 47, Score: 10.74\n",
      "Rank: 10, Product: 49, Score: 10.50\n",
      "Rank: 11, Product: 54, Score: 10.44\n",
      "Rank: 12, Product: 52, Score: 10.42\n",
      "Rank: 13, Product: 51, Score: 10.30\n",
      "Rank: 14, Product: 60, Score: 10.25\n",
      "Rank: 15, Product: 58, Score: 9.46\n",
      "\n",
      "Category: Beauty\n",
      "Rank: 1, Product: 65, Score: 11.32\n",
      "Rank: 2, Product: 67, Score: 11.12\n",
      "Rank: 3, Product: 63, Score: 10.63\n",
      "Rank: 4, Product: 61, Score: 10.24\n",
      "Rank: 5, Product: 66, Score: 10.21\n",
      "Rank: 6, Product: 69, Score: 10.06\n",
      "Rank: 7, Product: 73, Score: 9.93\n",
      "Rank: 8, Product: 68, Score: 9.84\n",
      "Rank: 9, Product: 74, Score: 9.63\n",
      "Rank: 10, Product: 64, Score: 9.60\n",
      "Rank: 11, Product: 70, Score: 9.49\n",
      "Rank: 12, Product: 71, Score: 9.45\n",
      "Rank: 13, Product: 72, Score: 9.35\n",
      "Rank: 14, Product: 62, Score: 8.76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(user_id, num_per_category=5):\n",
    "\n",
    "    user_interactions = interaction_df[interaction_df['user_id'] == user_id]['product_id'].tolist()\n",
    "\n",
    "    # Content-Based Filtering\n",
    "    product_indices = product_df[product_df['product_id'].isin(user_interactions)].index\n",
    "    content_based_scores = normalized_scores[product_indices].sum(axis=0)\n",
    "\n",
    "    # Collaborative Filtering\n",
    "    cf_scores = np.zeros(num_products)\n",
    "    for prod_id in range(num_products):\n",
    "        cf_scores[prod_id] = cf_model.predict(user_id, prod_id).est\n",
    "\n",
    "    # Deep Learning\n",
    "    dl_input = np.array([[user_id]] * num_products)  # Repeat user_id for all products\n",
    "    dl_scores = model.predict([dl_input, np.arange(num_products)])\n",
    "\n",
    "    # Combine the scores from different models\n",
    "    combined_scores = content_based_scores + cf_scores + dl_scores.flatten()\n",
    "\n",
    "    # Create a dataframe for combined scores\n",
    "    combined_scores_df = pd.DataFrame({'product_id': np.arange(num_products), 'combined_score': combined_scores})\n",
    "\n",
    "    # Get all products from each category with scores\n",
    "    products_per_category = {}\n",
    "    for category in categories:\n",
    "      category_products = product_df[product_df['category'] == category]\n",
    "      category_product_ids = category_products['product_id'].tolist()\n",
    "\n",
    "      valid_product_ids = combined_scores_df[combined_scores_df['product_id'].isin(category_product_ids)]['product_id']\n",
    "      products = [(product_id, combined_scores_df.loc[combined_scores_df['product_id'] == product_id, 'combined_score'].values[0]) for product_id in valid_product_ids]\n",
    "\n",
    "      # Sort products by score in descending order\n",
    "      sorted_products = sorted(products, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "      products_per_category[category] = sorted_products\n",
    "\n",
    "    return products_per_category, combined_scores_df\n",
    "\n",
    "# Example usage\n",
    "user_id = 21\n",
    "recommended_products_per_category, combined_scores_df = get_recommendations(user_id, num_per_category=5)\n",
    "\n",
    "# Print all products with ranking for each category\n",
    "for category, products in recommended_products_per_category.items():\n",
    "    print(f\"Category: {category}\")\n",
    "    for rank, (product_id, score) in enumerate(products, start=1):\n",
    "        product_info = product_df.loc[product_id]\n",
    "        print(f\"Rank: {rank}, Product: {product_id}, Score: {score:.2f}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "617e93f6-5e6c-41d1-a443-cdd55cc054a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "Top Recommended Products:\n",
      "Rank: 1, Product ID: 43, Score: 12.18\n",
      "Rank: 2, Product ID: 50, Score: 11.71\n",
      "Rank: 3, Product ID: 59, Score: 11.67\n",
      "Rank: 4, Product ID: 13, Score: 11.55\n",
      "Rank: 5, Product ID: 12, Score: 11.41\n",
      "Rank: 6, Product ID: 3, Score: 11.40\n",
      "Rank: 7, Product ID: 6, Score: 11.33\n",
      "Rank: 8, Product ID: 65, Score: 11.32\n",
      "Rank: 9, Product ID: 48, Score: 11.32\n",
      "Rank: 10, Product ID: 5, Score: 11.30\n",
      "Rank: 11, Product ID: 53, Score: 11.21\n",
      "Rank: 11, Product ID: 17, Score: 0.50\n",
      "Rank: 11, Product ID: 29, Score: 0.50\n",
      "Rank: 11, Product ID: 4, Score: 0.50\n",
      "Rank: 11, Product ID: 27, Score: 0.50\n",
      "Rank: 11, Product ID: 73, Score: 0.50\n",
      "Rank: 11, Product ID: 48, Score: 0.50\n",
      "Rank: 11, Product ID: 65, Score: 0.50\n",
      "Rank: 11, Product ID: 1, Score: 0.50\n",
      "Rank: 11, Product ID: 56, Score: 0.50\n",
      "Rank: 11, Product ID: 26, Score: 0.50\n",
      "Rank: 11, Product ID: 15, Score: 0.50\n"
     ]
    }
   ],
   "source": [
    "# similar to cart as well\n",
    "def get_recommendations(user_id, num_recommendations=11):\n",
    "    user_interactions = interaction_df[interaction_df['user_id'] == user_id]['product_id'].tolist()\n",
    "\n",
    "    # Check if the user has no past interactions\n",
    "    if not user_interactions:\n",
    "        # Get the products with the most interactions\n",
    "        popular_products = interaction_df['product_id'].value_counts().index.tolist()\n",
    "\n",
    "        # Recommend the top N most popular products\n",
    "        recommended_product_ids = popular_products[:num_recommendations]\n",
    "\n",
    "        return recommended_product_ids\n",
    "\n",
    "    # Content-Based Filtering\n",
    "    product_indices = product_df[product_df['product_id'].isin(user_interactions)].index\n",
    "    content_based_scores = normalized_scores[product_indices].sum(axis=0)\n",
    "\n",
    "    # Collaborative Filtering\n",
    "    cf_scores = np.zeros(num_products)\n",
    "    for prod_id in range(num_products):\n",
    "        cf_scores[prod_id] = cf_model.predict(user_id, prod_id).est\n",
    "\n",
    "    # Deep Learning\n",
    "    dl_input = np.array([[user_id]] * num_products)  # Repeat user_id for all products\n",
    "    dl_scores = model.predict([dl_input, np.arange(num_products)])\n",
    "\n",
    "    # Combine the scores from different models\n",
    "    combined_scores = content_based_scores + cf_scores + dl_scores.flatten()\n",
    "\n",
    "    # Create a dataframe for combined scores\n",
    "    combined_scores_df = pd.DataFrame({'product_id': np.arange(num_products), 'combined_score': combined_scores})\n",
    "\n",
    "    # Sort products by combined score in descending order\n",
    "    sorted_products = combined_scores_df.sort_values(by='combined_score', ascending=False)\n",
    "\n",
    "    # Get the top N recommendations\n",
    "    top_recommendations = sorted_products.head(num_recommendations)\n",
    "\n",
    "    # Get product IDs, scores, and ranks for the top recommendations\n",
    "    recommended_product_info = []\n",
    "    for rank, row in enumerate(top_recommendations.itertuples(), start=1):\n",
    "        product_id = row.product_id\n",
    "        score = row.combined_score\n",
    "        recommended_product_info.append((rank, product_id, score))\n",
    "\n",
    "    # Recommend products similar to those in the cart\n",
    "    cart_items = cart_df[cart_df['user_id'] == user_id]['product_id'].tolist()\n",
    "    if cart_items:\n",
    "        similar_product_ids = find_similar_products(cart_items, num_recommendations)\n",
    "        for product_id in similar_product_ids:\n",
    "            recommended_product_info.append((rank, product_id, 0.5))  # Lower score for cart-similar products\n",
    "\n",
    "    return recommended_product_info\n",
    "\n",
    "\n",
    "def find_similar_products(product_ids, num_recommendations):\n",
    "    # For demonstration purposes, let's just return a random selection of product IDs\n",
    "    similar_product_ids = np.random.choice(product_df['product_id'], num_recommendations, replace=False)\n",
    "    return similar_product_ids\n",
    "\n",
    "\n",
    "user_id = 21\n",
    "recommended_product_info = get_recommendations(user_id, num_recommendations=11)\n",
    "\n",
    "# Print the recommended product information\n",
    "print(\"Top Recommended Products:\")\n",
    "for rank, product_id, score in recommended_product_info:\n",
    "    print(f\"Rank: {rank}, Product ID: {product_id}, Score: {score:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e02627a2-4c79-4e2e-8d90-db8d078e3b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birthdates of users related to user 1: [datetime.date(2000, 2, 18), datetime.date(1962, 12, 9), datetime.date(2001, 8, 30)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a dictionary to relate users and their birthdates\n",
    "user_birthdates = {\n",
    "    1: user_df[user_df['user_id'].isin([42, 11, 21])]['birth_date'].tolist()\n",
    "}\n",
    "\n",
    "# Function to get related users' birthdates for a given user ID\n",
    "def get_related_users_birthdates(user_id):\n",
    "    return user_birthdates.get(user_id, [])\n",
    "\n",
    "# Example usage\n",
    "user_id_to_check = 1\n",
    "related_users_birthdates = get_related_users_birthdates(user_id_to_check)\n",
    "\n",
    "if related_users_birthdates:\n",
    "    print(f\"Birthdates of users related to user {user_id_to_check}: {related_users_birthdates}\")\n",
    "else:\n",
    "    print(f\"No related users' birthdates found for user {user_id_to_check}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c62cd86b-df6e-4e01-a31f-e91b7728d6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upcoming Birthdays:\n",
      "Related User ID: 42, Birthdate: 2023-08-30\n"
     ]
    }
   ],
   "source": [
    "def get_upcoming_birthdates(user_id, days=15):\n",
    "    today = datetime.today().date()\n",
    "    upcoming_birthdates = []\n",
    "\n",
    "    for related_user_id in user_relationships.get(user_id, []):\n",
    "        birthdate_related_user = user_df[user_df['user_id'] == related_user_id]['birth_date'].iloc[0]\n",
    "\n",
    "        # Calculate the next birthday\n",
    "        next_birthday_year = today.year\n",
    "        next_birthday = birthdate_related_user.replace(year=next_birthday_year)\n",
    "\n",
    "        # If next birthday is in the past, adjust the year\n",
    "        if next_birthday < today:\n",
    "            next_birthday_year += 1\n",
    "            next_birthday = next_birthday.replace(year=next_birthday_year)\n",
    "\n",
    "        days_until_birthday = (next_birthday - today).days\n",
    "        if 0 <= days_until_birthday <= days:\n",
    "            upcoming_birthdates.append((related_user_id, next_birthday))\n",
    "\n",
    "    return upcoming_birthdates\n",
    "\n",
    "# User relationships dictionary mapping user IDs to related user IDs and birthdates\n",
    "user_relationships = {\n",
    "    1: [42, 11, 7],\n",
    "    # Add other user relationships here\n",
    "}\n",
    "\n",
    "user_id = 1\n",
    "upcoming_birthdates = get_upcoming_birthdates(user_id)\n",
    "\n",
    "print(\"Upcoming Birthdays:\")\n",
    "for related_user_id, birthdate in upcoming_birthdates:\n",
    "    print(f\"Related User ID: {related_user_id}, Birthdate: {birthdate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a4479ff-d7c0-471b-9abd-14da78bf4327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Gift Products:\n",
      "{'user_id_birthday_boy': 42, 'birthdate': datetime.date(2023, 8, 30), 'product_id': 37, 'name': 'Greek Yogurt', 'category': 'Groceries', 'price': 395, 'brand': 'Bass, Clark and Allen'}\n",
      "{'user_id_birthday_boy': 42, 'birthdate': datetime.date(2023, 8, 30), 'product_id': 11, 'name': 'Smartwatch', 'category': 'Electronics', 'price': 456, 'brand': 'Palmer-Lambert'}\n",
      "{'user_id_birthday_boy': 42, 'birthdate': datetime.date(2023, 8, 30), 'product_id': 12, 'name': 'Bluetooth Speaker', 'category': 'Electronics', 'price': 473, 'brand': 'Hogan, Barnes and Pacheco'}\n",
      "{'user_id_birthday_boy': 42, 'birthdate': datetime.date(2023, 8, 30), 'product_id': 51, 'name': 'Blouse', 'category': 'Clothes', 'price': 67, 'brand': 'Randall, Johnston and Stone'}\n"
     ]
    }
   ],
   "source": [
    "def get_birthday_gifts(upcoming_birthdays, user_id_gift_giver, num_recommendations=5):\n",
    "    gift_recommendations = []\n",
    "\n",
    "    for user_id_birthday_boy, birthdate in upcoming_birthdays:\n",
    "        # Get user's cart items\n",
    "        cart_items_birthday_boy = set(cart_df[cart_df['user_id'] == user_id_birthday_boy]['product_id'])\n",
    "\n",
    "        # Get user's interacted items\n",
    "        interacted_items_birthday_boy = set(interaction_df[interaction_df['user_id'] == user_id_birthday_boy]['product_id'])\n",
    "\n",
    "        # Recommend products similar to cart items\n",
    "        similar_cart_items = set(find_similar_products(list(cart_items_birthday_boy), num_recommendations))\n",
    "\n",
    "        # Combine cart items, interacted items, and similar items\n",
    "        combined_items = cart_items_birthday_boy | interacted_items_birthday_boy | similar_cart_items\n",
    "\n",
    "        # Filter out items that the gift giver has interacted with\n",
    "        combined_items -= interacted_items_birthday_boy\n",
    "\n",
    "        # Recommend products for gifting\n",
    "        for item_id in combined_items:\n",
    "            # Get the product information from the product dataframe\n",
    "            product_info = product_df[product_df['product_id'] == item_id].iloc[0]\n",
    "            gift_recommendations.append({\n",
    "                'user_id_birthday_boy': user_id_birthday_boy,\n",
    "                'birthdate': birthdate,\n",
    "                'product_id': item_id,\n",
    "                'name': product_info['name'],\n",
    "                'category': product_info['category'],\n",
    "                'price': product_info['price'],\n",
    "                'brand': product_info['brand']\n",
    "            })\n",
    "\n",
    "    return gift_recommendations\n",
    "\n",
    "# Example usage\n",
    "user_id_gift_giver = 1\n",
    "upcoming_birthdays = get_upcoming_birthdates(user_id_gift_giver)\n",
    "gift_recommendations = get_birthday_gifts(upcoming_birthdays, user_id_gift_giver)\n",
    "\n",
    "# Print the recommended gift products\n",
    "print(\"Recommended Gift Products:\")\n",
    "for recommendation in gift_recommendations:\n",
    "    print(recommendation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a04adf-0300-418a-a44d-5509ec7a7b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hp\\miniconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c31dada-aaef-4178-a2dc-60964cfa4527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 - 1s - loss: 20.2576 - val_loss: 14.2453 - 759ms/epoch - 152ms/step\n",
      "Epoch 2/50\n",
      "5/5 - 0s - loss: 19.3961 - val_loss: 13.5560 - 35ms/epoch - 7ms/step\n",
      "Epoch 3/50\n",
      "5/5 - 0s - loss: 18.2131 - val_loss: 12.6644 - 44ms/epoch - 9ms/step\n",
      "Epoch 4/50\n",
      "5/5 - 0s - loss: 16.6850 - val_loss: 11.5300 - 37ms/epoch - 7ms/step\n",
      "Epoch 5/50\n",
      "5/5 - 0s - loss: 14.7529 - val_loss: 10.1171 - 39ms/epoch - 8ms/step\n",
      "Epoch 6/50\n",
      "5/5 - 0s - loss: 12.4564 - val_loss: 8.3979 - 47ms/epoch - 9ms/step\n",
      "Epoch 7/50\n",
      "5/5 - 0s - loss: 9.1633 - val_loss: 6.3899 - 46ms/epoch - 9ms/step\n",
      "Epoch 8/50\n",
      "5/5 - 0s - loss: 5.4458 - val_loss: 4.2652 - 40ms/epoch - 8ms/step\n",
      "Epoch 9/50\n",
      "5/5 - 0s - loss: 2.4175 - val_loss: 2.5126 - 43ms/epoch - 9ms/step\n",
      "Epoch 10/50\n",
      "5/5 - 0s - loss: 1.6292 - val_loss: 1.7048 - 36ms/epoch - 7ms/step\n",
      "Epoch 11/50\n",
      "5/5 - 0s - loss: 1.7140 - val_loss: 1.5764 - 35ms/epoch - 7ms/step\n",
      "Epoch 12/50\n",
      "5/5 - 0s - loss: 1.6600 - val_loss: 1.7549 - 39ms/epoch - 8ms/step\n",
      "Epoch 13/50\n",
      "5/5 - 0s - loss: 1.1670 - val_loss: 1.9665 - 39ms/epoch - 8ms/step\n",
      "Epoch 14/50\n",
      "5/5 - 0s - loss: 1.2020 - val_loss: 2.1135 - 35ms/epoch - 7ms/step\n",
      "Epoch 15/50\n",
      "5/5 - 0s - loss: 1.1008 - val_loss: 2.1551 - 40ms/epoch - 8ms/step\n",
      "Epoch 16/50\n",
      "5/5 - 0s - loss: 1.4857 - val_loss: 2.0383 - 36ms/epoch - 7ms/step\n",
      "Epoch 17/50\n",
      "5/5 - 0s - loss: 1.1824 - val_loss: 1.8535 - 45ms/epoch - 9ms/step\n",
      "Epoch 18/50\n",
      "5/5 - 0s - loss: 0.9347 - val_loss: 1.7510 - 40ms/epoch - 8ms/step\n",
      "Epoch 19/50\n",
      "5/5 - 0s - loss: 1.0974 - val_loss: 1.8285 - 36ms/epoch - 7ms/step\n",
      "Epoch 20/50\n",
      "5/5 - 0s - loss: 0.8468 - val_loss: 1.9593 - 39ms/epoch - 8ms/step\n",
      "Epoch 21/50\n",
      "5/5 - 0s - loss: 0.9317 - val_loss: 1.9780 - 41ms/epoch - 8ms/step\n",
      "Epoch 22/50\n",
      "5/5 - 0s - loss: 0.8431 - val_loss: 1.9093 - 39ms/epoch - 8ms/step\n",
      "Epoch 23/50\n",
      "5/5 - 0s - loss: 1.1130 - val_loss: 1.9148 - 40ms/epoch - 8ms/step\n",
      "Epoch 24/50\n",
      "5/5 - 0s - loss: 0.9675 - val_loss: 1.8992 - 37ms/epoch - 7ms/step\n",
      "Epoch 25/50\n",
      "5/5 - 0s - loss: 1.0804 - val_loss: 1.8934 - 36ms/epoch - 7ms/step\n",
      "Epoch 26/50\n",
      "5/5 - 0s - loss: 0.8323 - val_loss: 1.9747 - 34ms/epoch - 7ms/step\n",
      "Epoch 27/50\n",
      "5/5 - 0s - loss: 1.0447 - val_loss: 2.0757 - 39ms/epoch - 8ms/step\n",
      "Epoch 28/50\n",
      "5/5 - 0s - loss: 1.0557 - val_loss: 2.1089 - 41ms/epoch - 8ms/step\n",
      "Epoch 29/50\n",
      "5/5 - 0s - loss: 0.9155 - val_loss: 2.0491 - 42ms/epoch - 8ms/step\n",
      "Epoch 30/50\n",
      "5/5 - 0s - loss: 0.9441 - val_loss: 2.0072 - 36ms/epoch - 7ms/step\n",
      "Epoch 31/50\n",
      "5/5 - 0s - loss: 0.7666 - val_loss: 2.0486 - 40ms/epoch - 8ms/step\n",
      "Epoch 32/50\n",
      "5/5 - 0s - loss: 0.8269 - val_loss: 2.0424 - 38ms/epoch - 8ms/step\n",
      "Epoch 33/50\n",
      "5/5 - 0s - loss: 0.9655 - val_loss: 2.0261 - 36ms/epoch - 7ms/step\n",
      "Epoch 34/50\n",
      "5/5 - 0s - loss: 0.9051 - val_loss: 2.0123 - 40ms/epoch - 8ms/step\n",
      "Epoch 35/50\n",
      "5/5 - 0s - loss: 0.8789 - val_loss: 2.0324 - 38ms/epoch - 8ms/step\n",
      "Epoch 36/50\n",
      "5/5 - 0s - loss: 1.0830 - val_loss: 1.9975 - 39ms/epoch - 8ms/step\n",
      "Epoch 37/50\n",
      "5/5 - 0s - loss: 0.9426 - val_loss: 1.9285 - 38ms/epoch - 8ms/step\n",
      "Epoch 38/50\n",
      "5/5 - 0s - loss: 0.8903 - val_loss: 1.8677 - 37ms/epoch - 7ms/step\n",
      "Epoch 39/50\n",
      "5/5 - 0s - loss: 0.9589 - val_loss: 1.8362 - 37ms/epoch - 7ms/step\n",
      "Epoch 40/50\n",
      "5/5 - 0s - loss: 0.7438 - val_loss: 1.8030 - 39ms/epoch - 8ms/step\n",
      "Epoch 41/50\n",
      "5/5 - 0s - loss: 0.8144 - val_loss: 1.8595 - 36ms/epoch - 7ms/step\n",
      "Epoch 42/50\n",
      "5/5 - 0s - loss: 0.7665 - val_loss: 1.8651 - 37ms/epoch - 7ms/step\n",
      "Epoch 43/50\n",
      "5/5 - 0s - loss: 0.7159 - val_loss: 1.7692 - 41ms/epoch - 8ms/step\n",
      "Epoch 44/50\n",
      "5/5 - 0s - loss: 0.8434 - val_loss: 1.7292 - 36ms/epoch - 7ms/step\n",
      "Epoch 45/50\n",
      "5/5 - 0s - loss: 0.9071 - val_loss: 1.8337 - 37ms/epoch - 7ms/step\n",
      "Epoch 46/50\n",
      "5/5 - 0s - loss: 0.9338 - val_loss: 2.0132 - 35ms/epoch - 7ms/step\n",
      "Epoch 47/50\n",
      "5/5 - 0s - loss: 0.7980 - val_loss: 1.9112 - 38ms/epoch - 8ms/step\n",
      "Epoch 48/50\n",
      "5/5 - 0s - loss: 0.9453 - val_loss: 1.7480 - 40ms/epoch - 8ms/step\n",
      "Epoch 49/50\n",
      "5/5 - 0s - loss: 0.9829 - val_loss: 1.7684 - 37ms/epoch - 7ms/step\n",
      "Epoch 50/50\n",
      "5/5 - 0s - loss: 0.8510 - val_loss: 1.8466 - 38ms/epoch - 8ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "RMSE: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\miniconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Flatten, Dense, Concatenate, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load your data (assuming you have the CSV files)\n",
    "user_df = pd.read_csv('user_data.csv')\n",
    "product_df = pd.read_csv('product_data.csv')\n",
    "interaction_df = pd.read_csv('interaction_data.csv')\n",
    "\n",
    "# Define the number of products\n",
    "num_users = len(user_df)\n",
    "num_products = len(product_df)\n",
    "\n",
    "# Create a dictionary to map user and product IDs to indices\n",
    "user_id_to_index = {user_id: index for index, user_id in enumerate(user_df['user_id'])}\n",
    "product_id_to_index = {product_id: index for index, product_id in enumerate(product_df['product_id'])}\n",
    "\n",
    "# Map user and product IDs in interaction data to their respective indices\n",
    "interaction_df['user_index'] = interaction_df['user_id'].map(user_id_to_index)\n",
    "interaction_df['product_index'] = interaction_df['product_id'].map(product_id_to_index)\n",
    "\n",
    "# Separate user and product inputs\n",
    "user_input = Sequential()\n",
    "user_input.add(Embedding(num_users, 50, input_length=1))\n",
    "\n",
    "product_input = Sequential()\n",
    "product_input.add(Embedding(num_products, 50, input_length=1))\n",
    "\n",
    "# Concatenate user and product embeddings\n",
    "merged = Concatenate()([user_input.output, product_input.output])\n",
    "flatten = Flatten()(merged)\n",
    "\n",
    "# Build the neural network for regression\n",
    "dl_model = Dense(128, activation='relu')(flatten)\n",
    "dl_model = Dropout(0.5)(dl_model)\n",
    "dl_model = Dense(64, activation='relu')(dl_model)\n",
    "dl_model = Dropout(0.5)(dl_model)\n",
    "dl_model = Dense(1, activation='linear')(dl_model)  # Linear activation for regression\n",
    "\n",
    "model = Model(inputs=[user_input.input, product_input.input], outputs=dl_model)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')  # Use mean squared error for regression\n",
    "\n",
    "# Map user and product indices to arrays for training\n",
    "user_indices = interaction_df['user_index'].values\n",
    "product_indices = interaction_df['product_index'].values\n",
    "train_labels = interaction_df['rating'].values\n",
    "\n",
    "# Train the deep learning model\n",
    "model.fit([user_indices, product_indices], train_labels, epochs=50, batch_size=32, validation_split=0.2, verbose=2)\n",
    "\n",
    "# Save the complete model using the model save function\n",
    "dl_model_path = 'dl_model.h5'\n",
    "model.save(dl_model_path)\n",
    "\n",
    "# Predict using the trained model\n",
    "test_predictions = model.predict([user_indices, product_indices])\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "rmse = mean_squared_error(train_labels, test_predictions, squared=False)\n",
    "print(f\"RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eeb2217f-b1ac-4b78-85ee-881d24a3e285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise.dataset import Dataset\n",
    "from surprise.reader import Reader\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load your interaction data\n",
    "interaction_df = pd.read_csv('interaction_data.csv')\n",
    "\n",
    "# Prepare data for Surprise library\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(interaction_df[['user_id', 'product_id', 'rating']], reader)\n",
    "\n",
    "# Build trainset\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Build and train a k-Nearest Neighbors collaborative filtering model\n",
    "cf_model = KNNBasic(k=50, sim_options={'user_based': False})\n",
    "cf_model.fit(trainset)\n",
    "\n",
    "# Save the collaborative filtering model using pickle\n",
    "cf_model_path = 'cf_model.pkl'\n",
    "with open(cf_model_path, 'wb') as file:\n",
    "    pickle.dump(cf_model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f6a9ee9e-1509-462a-9708-0554832aa329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5001\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [21/Aug/2023 01:41:06] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2023 01:41:06] \"GET /static/css/styles.css HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Aug/2023 01:41:10] \"POST /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2023 01:41:12] \"GET /friends/1 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2023 01:41:12] \"GET /static/css/friends.css HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Aug/2023 01:41:20] \"POST /recommendations HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2023 01:41:23] \"GET /friends/15 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2023 01:41:23] \"GET /static/css/friends.css HTTP/1.1\" 304 -\n"
     ]
    }
   ],
   "source": [
    "#finalmost-\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from flask import Flask, render_template, request, jsonify\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "def get_upcoming_birthdates(user_id, days=15):\n",
    "    today = datetime.today().date()\n",
    "    upcoming_birthdates = []\n",
    "\n",
    "    for related_user_id in user_relationships.get(user_id, []):\n",
    "        birthdate_related_user = user_df[user_df['user_id'] == related_user_id]['birth_date'].iloc[0]\n",
    "\n",
    "        # Convert birthdate string to a datetime object\n",
    "        birthdate_related_user = datetime.strptime(birthdate_related_user, '%Y-%m-%d').date()\n",
    "\n",
    "        # Calculate the next birthday\n",
    "        next_birthday_year = today.year\n",
    "        next_birthday = birthdate_related_user.replace(year=next_birthday_year)\n",
    "\n",
    "        # If next birthday is in the past, adjust the year\n",
    "        if next_birthday < today:\n",
    "            next_birthday_year += 1\n",
    "            next_birthday = birthdate_related_user.replace(year=next_birthday_year)\n",
    "\n",
    "        days_until_birthday = (next_birthday - today).days\n",
    "        if 0 <= days_until_birthday <= days:\n",
    "            upcoming_birthdates.append((related_user_id, next_birthday))\n",
    "\n",
    "    return upcoming_birthdates\n",
    "\n",
    "@app.route('/friends/<int:user_id>')\n",
    "def friends(user_id):\n",
    "    friends_list = user_relationships.get(user_id, [])\n",
    "    upcoming_birthdays = get_upcoming_birthdates(user_id)\n",
    "    gift_recommendations = get_birthday_gifts(upcoming_birthdays, user_id)\n",
    "\n",
    "    # Check if the user has any relationships\n",
    "    if not friends_list:\n",
    "        no_friends_message = \"You don't have any flipyFriends.\"\n",
    "        return render_template('friends.html', no_friends_message=no_friends_message)\n",
    "\n",
    "    return render_template('friends.html', friends=friends_list, upcoming_birthdays=upcoming_birthdays, gift_recommendations=gift_recommendations)\n",
    "\n",
    "@app.route('/recommendations', methods=['GET', 'POST'])\n",
    "def recommendations():\n",
    "    if request.method == 'POST':\n",
    "        try:\n",
    "            data = json.loads(request.data)\n",
    "            user_id = int(data['user_id'])\n",
    "\n",
    "            recommended_products_per_category, _ = get_recommendations(user_id)\n",
    "\n",
    "            recommended_product_info = []\n",
    "\n",
    "            for category, products in recommended_products_per_category.items():\n",
    "                for rank, (product_id, score) in enumerate(products, start=1):\n",
    "                    product_name = product_df.loc[product_id, 'name']\n",
    "                    recommended_product_info.append({\n",
    "                        'product_name': product_name,\n",
    "                        'product_id': product_id,\n",
    "                        'score': score,\n",
    "                        'category': category\n",
    "                    })\n",
    "\n",
    "            return jsonify(recommended_product_info)\n",
    "\n",
    "        except Exception as e:\n",
    "            error_message = f\"Error: {str(e)}\"\n",
    "            print(error_message)\n",
    "            return jsonify({'error': error_message})\n",
    "\n",
    "    else:\n",
    "        return \"Method Not Allowed\"\n",
    "\n",
    "def get_recommendations(user_id, num_recommendations=11):\n",
    "    user_interactions = interaction_df[interaction_df['user_id'] == user_id]['product_id'].tolist()\n",
    "    if not user_interactions:\n",
    "        popular_products = interaction_df['product_id'].value_counts().index.tolist()\n",
    "        recommended_product_ids = popular_products[:num_per_category]\n",
    "        return recommended_product_ids\n",
    "\n",
    "    product_indices = product_df[product_df['product_id'].isin(user_interactions)].index\n",
    "    content_based_scores = normalized_scores[product_indices].sum(axis=0)\n",
    "\n",
    "    cf_scores = np.zeros(num_products)\n",
    "    for prod_id in range(num_products):\n",
    "        cf_scores[prod_id] = cf_model.predict(user_id, prod_id).est\n",
    "    dl_model = load_model('dl_model.h5')\n",
    "    dl_input = np.array([[user_id]] * num_products)\n",
    "    dl_scores = dl_model.predict([dl_input, np.arange(num_products)]).flatten()\n",
    "\n",
    "    combined_scores = content_based_scores + cf_scores + dl_scores.flatten()\n",
    "\n",
    "    combined_scores_df = pd.DataFrame({'product_id': np.arange(num_products), 'combined_score': combined_scores})\n",
    "\n",
    "    products_per_category = {}\n",
    "    for category in categories:\n",
    "      category_products = product_df[product_df['category'] == category]\n",
    "      category_product_ids = category_products['product_id'].tolist()\n",
    "\n",
    "      valid_product_ids = combined_scores_df[combined_scores_df['product_id'].isin(category_product_ids)]['product_id']\n",
    "      products = [(product_id, combined_scores_df.loc[combined_scores_df['product_id'] == product_id, 'combined_score'].values[0]) for product_id in valid_product_ids]\n",
    "\n",
    "      # Sort products by score in descending order\n",
    "      sorted_products = sorted(products, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "      products_per_category[category] = sorted_products\n",
    "\n",
    "    return products_per_category, combined_scores_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f59cae-502d-45dc-acd2-3cd31ebd0a70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
